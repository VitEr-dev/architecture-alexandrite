«Архитектурное решение по логированию»

Логи помогают отслеживать работу системы и ее компонентов, находить ошибки, анализировать поведение пользователей, обеспечивать безопасность. 

Для фронтенда Internet Shop, CRM, MES логирование необходимо для отслеживания действий пользователей, ошибки и производительность. Основные логи: ошибки Vue/React/JavaScript /TypeScript (ошибки в компонентах, ошибки API – запросов); события пользователей; производительность (время загрузки страниц, медленные API-вызовы). 

Для бекэнда Shop API, CRM API, MES API логирование необходимо для отслеживания запросов, ошибок, бизнес-событий и работы с БД. Основные логи: HTTP-запросы/ответы (URL, метод, статус, время выполнения; бизнес-логика (создание и изменение статуса заказов); ошибки (ошибки валидации, 500-ошибки, таймауты). 

Для БД Shop DB, MES DB, 3D file storage логирование необходимо для отслеживания производительности, ошибок, потенциальных угроз. Основные логи для БД: логи запросов (все SQLзапросы, включая время выполнения); логи ошибок (ошибки синтаксиса, проблемы подключений, нарушение ограничений); логи транзакций (начало/завершение транзакции, откаты, длительные транзакции); логи подключений (кто подключился (IP,  пользователь), неудачные попытки входа (подозрительная активность); аудит-логи (изменения схемы БД, доступ к чувствительным данным, действия администраторов); логи конфигурации (репликации и шардинга). 

Для RabbitMQ логирование необходимо для отслеживания работы очередей, диагностики проблем с сообщениями и обеспечения стабильности системы. Основные логи: логи подключений (успешные/неудачные подключения клиентов (IP, порт, логин), разрывы соединений); логи каналов (создание/закрытие каналов, ошибки обработки сообщений); логи очередей (создание/удаление очередей, сообщения в dead letter queue (DLQ), проблемы с доставкой); логи сообщений, если есть на это ресурсы (публикацию/потребление сообщений, ошибки маршрутизации); логи кластера (репликация между узлами, конфликты)

В качестве логов уровня INFO нам необходимы логи об изменении статуса заказов клиентов в соответствии с бизнес-процессом:
INITIATED [онлайн-магазин] — пользователь завёл новый заказ или положил товары в пустую корзину.
FILE_UPLOADED [Internet Shop] — пользователь (В2С) загрузил файл с 3D-моделью или создал его с помощью конструктора.
FILE_UPLOADED [MES API] — пользователь (B2B) загрузил файл с 3D-моделью через выставленный API.
SUBMITTED [онлайн-магазин] — пользователь нажал на кнопку «Сделать заказ».
PRICE_CALCULATED [MES] — система посчитала стоимость заказа.
MANUFACTURING_APPROVED [CRM] — заказ подтверждён, его можно отдавать в производство.
MANUFACTURING_STARTED [MES] — оператор взял заказ в работу.
MANUFACTURING_COMPLETED [MES] — оператор выполнил заказ.
PACKAGING [MES] — оператор начал упаковывать заказ.
SHIPPED [MES] — заказ отправлен покупателю.
CLOSED [CRM] — заказ завершён. Он закрывается после получения сообщения от транспортной компании или вручную.
В логе должны быть user_id, order_id, order_status, timestamp. 

Логи успешного старта или остановки сервиса, включающие: service, status, timestamp. 

Логи авторизации пользователей системы: user_id, IP, timestamp

Логи HTTP запросов пользователей: user_id, request_id, timestamp. 

Необходимо использовать другие уровни логов:

FATAL: критическая ошибка – отказ сервиса и БД системы
ERROR: ошибка одной функции, но без нарушения работы сервиса и БД системы
WARNING: потенциальная проблема, которая не прерывает работу системы
DEBUG: отладочная информация для разработчика (в средах dev, release)
TRACE: максимально детальные логи для отладки сложных багов для разработчика (в средах dev, release)

Мотивация

Как было сформулировано в ответах на предыдущие задания, невозможно решить проблемы с «потерей» заказов в приложении, идентифицировать проблемы и причины и «чинить» проактивно, до того как клиент узнает сам и пожалуется, без объективной информации о том, как функционирует каждый сервис и Система в целом.  Для этого необходимо повысить уровень наблюдаемости (observability) Системы за счет создания:
- системы мониторинга;
- системы логирования;
- трассировки заказов клиентов. 

В результате логирования мы получим детальные данные о проблемах. Использование логов одновременно с данными мониторинга и трассировки позволит в комплексе отследить и проанализировать проблемы и причины из возникновения. 

Влияние на метрики системы:

- Количество ошибок: метрики важны для бизнеса для поддержания требуемого уровня SLA, так как показывают количество ошибок при выполнении запросов пользователей

- Длительность выполнения запросов: метрики важна для бизнеса для поддержания требуемого уровня SLA и для улучшения клиентского опыта. 

 - Технические: повышение надежности и производительности системы, отслеживание действий пользователей. 

В нашей ситуации у команды ограничены ресурсы и надо выбирать и расставлять приоритеты сервисов, которые необходимо подключить к трассировке и логированию в первую очередь. Такими сервисами являются бекэнд [Shop API, CRM API, MES API], БД [Shop DB, MES DB, 3D file storage] и RabbitMQ. Здесь мы можем идентифицировать проблемы с исполнением заказов пользователей и найти решение критичной проблеме бизнеса. 


Предлагаемое решение

В рамках выполнения предыдущих заданий уже выбраны:

Для мониторинга Prometheus и Grafana
Для трассировки OpenTelemetry и Jaeger

Для логирования будем использовать стек ELK. Стек включает компоненты: Filebeat (агент на компонентах системы, отправляющий данные в Logstash); Logstash (сбор/преобразование данных, передача данных в Elasticsearch); Elasticsearch (NoSQL база данных); Kibana (инструмент для визуализации данных из Elasticsearch)

Разумным представляется собирать данные с компонентов системы для мониторинга, логирования и трассировки не посредством отдельных агентов/интеграции для каждой задачи, а посредством одного агента/интеграции (сможем уменьшить дублирование данных, снизить нагрузку на систему). Для этой задачи подходит OpenTelemetry. Каждый компонент системы будет подключен к OpenTelemetry SDK, данные от OpenTelemetry SDK поступают в OpenTelemetry Collertor, трансформируются и передаются в Prometheus и ELK. 

Общее Предлагаемое решение для мониторинга, трассировки и логирования Системы Александрита представлено: 

https://drive.google.com/file/d/1bitj0PqJd1ZFeItkQX7UHyjYW2wZg_pL/view?usp=sharing


Политика безопасности в отношении логов

Необходимо обеспечить снижение рисков утечки чувствительных данных и несанкционированного доступа. Ключевые моменты:

 -Персональные и чувствительные данные при логировании необходимо максировать. 
 -Не надо логировать тела трассируемых запросов. 
 -При передаче данных от компонентов в систему логирования не использовать открытые протоколы HTTP/gRPC, а использовать TLS для всех соединений, mTLS – аутентификацию для всех компонентов 
 -Необходимо проработать авторизацию пользователей к системам мониторинга, логирования, трассировки например, через OAuth/OpenID Connect. Проработать ролевую модель доступа


Политика хранения логов и построения индексов

Необходимо выработать и согласовать с бизнесом политику в отношении хранения и очистки логов (сроки хранения и периодичность удаления логов может быть определена из целей бизнеса, например, удаление логов через 30 дней или сохранение на ленте)

Представляется разумным делать отдельные индексы по компоненты системы, так как используются разные типы данных, различаются SLA и нагрузки, и требования по безопасности (если необходима изолированность индекса для отдельных групп пользователей в соответствии с ролевой моделью). 

Рекомендуемый размер индекса Elasticsearch зависит от данных, нагрузки и аппаратных ресурсов.  Для временных данных (с ротацией по времени ~ 7 дней) до 30 Гб. Для стандартных индексов (система, клиент, заказ) 20-50 Гб из расчета на один шард. 


Система сбора логов -> Система анализа логов

Алертинг обязательно необходим, иначе мы продолжим узнавать о проблемах не первыми, а от клиентов. 

Если использовать стек ELK, на базе логов и , например, готовых правил в Kibana Alerting или кастомизированных, ELK Watcher (для кастомных сценариев), можно настроить важные алерты: критичные ошибки системы (HTTP 500 превышают заданный уровень), критичные проблемы с инфраструктурой (недоступность БД, заполнение диска, высокая загрузка CPU), аномалии в бизнес-логике (резкий рост отмен заказов или резкий рост созданных заказов). 

Алертинг надо настраивать в комплексе, на основе данных мониторинга и логирования. 
